{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d1l1th1um/Desktop/demo/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.56.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/Mini-InternVL2-2B-DA-Medical:\n",
      "- configuration_intern_vit.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/Mini-InternVL2-2B-DA-Medical:\n",
      "- configuration_internlm2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/OpenGVLab/Mini-InternVL2-2B-DA-Medical:\n",
      "- configuration_internvl_chat.py\n",
      "- configuration_intern_vit.py\n",
      "- configuration_internlm2.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'architectures'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load model directly\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOpenGVLab/Mini-InternVL2-2B-DA-Medical\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/demo/env/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:549\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    547\u001b[39m     _ = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mquantization_config\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m config, kwargs = \u001b[43mAutoConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig.get(\u001b[33m\"\u001b[39m\u001b[33mtorch_dtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/demo/env/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1306\u001b[39m, in \u001b[36mAutoConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[39m\n\u001b[32m   1302\u001b[39m     config_class = get_class_from_dynamic_module(\n\u001b[32m   1303\u001b[39m         class_ref, pretrained_model_name_or_path, code_revision=code_revision, **kwargs\n\u001b[32m   1304\u001b[39m     )\n\u001b[32m   1305\u001b[39m     config_class.register_for_auto_class()\n\u001b[32m-> \u001b[39m\u001b[32m1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconfig_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1307\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[32m   1308\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/demo/env/lib/python3.12/site-packages/transformers/configuration_utils.py:640\u001b[39m, in \u001b[36mPretrainedConfig.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[39m\n\u001b[32m    634\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m] != \u001b[38;5;28mcls\u001b[39m.model_type:\n\u001b[32m    635\u001b[39m         logger.warning(\n\u001b[32m    636\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[33m'\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to instantiate a model of type \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    637\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.model_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    638\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/demo/env/lib/python3.12/site-packages/transformers/configuration_utils.py:839\u001b[39m, in \u001b[36mPretrainedConfig.from_dict\u001b[39m\u001b[34m(cls, config_dict, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m to_remove:\n\u001b[32m    837\u001b[39m     kwargs.pop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel config \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconfig\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_unused_kwargs:\n\u001b[32m    841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m config, kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/demo/env/lib/python3.12/site-packages/transformers/configuration_utils.py:873\u001b[39m, in \u001b[36mPretrainedConfig.__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_json_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/demo/env/lib/python3.12/site-packages/transformers/configuration_utils.py:985\u001b[39m, in \u001b[36mPretrainedConfig.to_json_string\u001b[39m\u001b[34m(self, use_diff)\u001b[39m\n\u001b[32m    973\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    974\u001b[39m \u001b[33;03mSerializes this instance to a JSON string.\u001b[39;00m\n\u001b[32m    975\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    982\u001b[39m \u001b[33;03m    `str`: String containing all the attributes that make up this configuration instance in JSON format.\u001b[39;00m\n\u001b[32m    983\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_diff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m985\u001b[39m     config_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_diff_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    987\u001b[39m     config_dict = \u001b[38;5;28mself\u001b[39m.to_dict()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/demo/env/lib/python3.12/site-packages/transformers/configuration_utils.py:893\u001b[39m, in \u001b[36mPretrainedConfig.to_diff_dict\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    890\u001b[39m default_config_dict = PretrainedConfig().to_dict()\n\u001b[32m    892\u001b[39m \u001b[38;5;66;03m# get class specific config dict\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m893\u001b[39m class_config_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.to_dict() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_no_defaults_at_init \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    895\u001b[39m serializable_config_dict = {}\n\u001b[32m    897\u001b[39m \u001b[38;5;66;03m# Only serialize values that differ from the default config,\u001b[39;00m\n\u001b[32m    898\u001b[39m \u001b[38;5;66;03m# except always keep the 'config' attribute.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/huggingface/modules/transformers_modules/OpenGVLab/Mini-InternVL2-2B-DA-Medical/f416ce72f89d374a0a0c4c893b01cb43d7a632d5/configuration_internvl_chat.py:50\u001b[39m, in \u001b[36mInternVLChatConfig.__init__\u001b[39m\u001b[34m(self, vision_config, llm_config, use_backbone_lora, use_llm_lora, select_layer, force_image_size, downsample_ratio, template, dynamic_image_size, use_thumbnail, ps_version, min_dynamic_patch, max_dynamic_patch, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     logger.info(\u001b[33m'\u001b[39m\u001b[33mllm_config is None. Initializing the LlamaConfig config with default values (`LlamaConfig`).\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m.vision_config = InternVisionConfig(**vision_config)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mllm_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43marchitectures\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[32m0\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mLlamaForCausalLM\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     51\u001b[39m     \u001b[38;5;28mself\u001b[39m.llm_config = LlamaConfig(**llm_config)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m llm_config[\u001b[33m'\u001b[39m\u001b[33marchitectures\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mInternLM2ForCausalLM\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'architectures'"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"OpenGVLab/Mini-InternVL2-2B-DA-Medical\", trust_remote_code=True, torch_dtype=\"auto\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
